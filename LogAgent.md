# LogAgent

로그 파일 입수 프로그램<br/>
지정된 디렉토리 내 파일을 모니터링하여 증분에 대해 kafka 전송<br/>
(신규 로그 입수시 RakeAPI 권장, 예외적인 경우에만 사용)<br/>

## db-data 입수용으로 사용 시
원본 DB의 테이블을 DIC 클러스터로 연동하기 위하여 사용하는 방법 중 하나 입니다. 합의된 Landing 서버에 미리 정의된 파일 이름으로 파일을 생성해주셔야 합니다. 그리고 Landing 서버에 LogAgent 데몬을 띄워 파일을 DIC 클러스터에 적재합니다.

### 장점
* LogAgent가 디렉토리를 모니터링하고 있기 때문에 예정 시간보다 늦거나 빨리 파일을 생성하더라도 별도의 대응이 필요 없습니다.

### 제약 사항
* 데이터 추출 및 파일 생성을 입수 요청 팀에서 진행해야 합니다. 추출 시 기본적인 변환, 클랜징 작업도 진행해야 합니다.
* 테이블 스키마 외에 첫번째 필드에 추출기준일자 메타 필드를 붙여야 합니다.
    - 자세한 설명은 아래 파일 생성 가이드 참조
* 추출에 문제가 있어 파일을 재추출해야할 때에는 DIC 클러스터에 전송된 파일을 먼저 삭제하도록 DI팀에 요청한 후 작업해야 합니다. (매우 불편합니다.) DI팀에서 조치해주지 않고 파일을 재생성하면 중복 레코드가 발생합니다.

### 신청 절차
1. 프로젝트 생성
    - 연동 요청자는 BM별로 DE팀 담당자와 컨택하여 연동해야할 원본 DB의 테이블을 지정합니다.
    - 연동 요청자는 [DI팀 JIRA 고객센터](http://jira.skplanet.com/servicedesk/customer/portal/49) 를 통해 신규 데이터 입수를 요청합니다. DI팀과 상의해 [센티넬](http://sentinel.skplanet.com:8080)에서 인터페이스 정의서를 작성할 프로젝트를 지정합니다.
        + 프로젝트 명칭
        + Entity 정보 (P1, P2, P3)
        + db-data 연동 방법
        + Hive DB (적절한 DB가 없으면 신규 생성 [가이드](http://wiki.skplanet.com/pages/viewpage.action?pageId=63275727))
2. db-data 정의
    - 센티넬 프로젝트에 인터페이스 정의서를 (추가) 작성합니다.
    - [센티넬 프로젝트 작성 메뉴얼](http://sentinel.skplanet.com:8080/docs/dbschema)
3. 연동 준비
    - 연동 방법이 LogAgent로 결정되면 연동 요청자는 Landing 서버를 준비합니다.
    - 연동 요청자는 테이블로부터 스냅샷 파일을 추출하는 어플리케이션을 (사용 or 개발) & 운영합니다.
    - 연동 요청자는 아래와 같이 LogAgent 설치를 ITSM, 보안포털을 통해 진행합니다.
        + 보안포털에서
            * 랜딩서버, 브로커 클러스터간 방화벽 신청
상용존 랜딩 서버 => 상용 브로커 설정시
|IP               |Port                   |
|-----------------|----------------------:|
|172.22.212.21~30 |2181, 9092, 9999, 10000|
|172.22.206.98(L4)|8080                   |
개발존 랜딩 서버 => 개발 브로커 설정시
|IP              |Port                         |
|----------------|----------------------------:|
|172.21.0.101~105|2181, 9000, 9092, 9999, 10000|
        + ITSM에서 
            * logagent 계정 생성
            * logagent 계정 dump location 접근 권한 확인
            * logagent 계정 홈디렉토리에 logagent 최신버전 설치 요청
            * 랜딩서버에 /etc/hosts 호스트 등록 요청
상용존 랜딩 서버 => 상용 브로커 설정시
~~~~
172.22.212.21   DICc-broker01-172.cm.skp
172.22.212.22   DICc-broker02-172.cm.skp
172.22.212.23   DICc-broker03-172.cm.skp
172.22.212.24   DICc-broker04-172.cm.skp
172.22.212.25   DICc-broker05-172.cm.skp
172.22.212.26   DICc-broker06-172.cm.skp
172.22.212.27   DICc-broker07-172.cm.skp
172.22.212.28   DICc-broker08-172.cm.skp
172.22.212.29   DICc-broker09-172.cm.skp
172.22.212.30   DICc-broker10-172.cm.skp
~~~~
개발존 랜딩 서버 => 개발 브로커 설정시
~~~~
172.21.0.101    dici-devbroker01.is.skp
172.21.0.102    dici-devbroker02.is.skp
172.21.0.103    dici-devbroker03.is.skp
172.21.0.104    dici-devbroker04.is.skp
172.21.0.105    dici-devbroker05.is.skp
~~~~

    - DI팀은 센티넬 프로젝트 내 인터페이스 정의서를 참고해 LogAgent 설정을 세팅합니다.

4. 입수 요청
    - 추출 파일 생성 & 전달 후, JIRA에서 코멘트로 입수를 요청합니다.
    - DI팀은 센티넬 프로젝트 내 인터페이스 정의서를 참고해 LogAgent를 시동합니다.

### 추출 파일 생성 가이드
* 파일 명은 주기별로 생성되도록 아래 형태로 생성합니다.
    - [DATA_ID]_[추출기준일자].tsv
* tsv 포멧: 필드 구분자 탭 ("\t"), 레코드 구분자 개행문자 ("\n") 형태로 생성합니다.
* 필드 내 개행문자 ("\n"), 탭 ("\t") 제거해주십시오.
* 모든 레코드의 첫번째 필드에 추출기준일자 추가
    - 추출기준일자는 통계 도출 시 기준이 되는 일자를 말합니다.
    - 예를들면 20160616일자 구매 내역 통계를 도출하기 위해 20160616 구매 이력을 추출할 때, 추출하는 모든 레코드의 첫번째 필드에 20160616 값을 넣어주시면 됩니다.
    - 추출 작업은 자정 이후에 이루어 지므로 추출 시점 기준 D-1 값을 넣어주시면 됩니다. (20160617일에 20160616 레코드를 추출)
* 추출 유형에 따른 레코드 필터링
    - full (전체)
        + 테이블 전체 추출합니다.
    - delta (변동분)
        + 레코드 생성 일자 & 업데이트 일자 필드가 있을 경우 두 필드 중 하나라도 값이 D-1인 레코드만 추출합니다.
    - incremental (증분)
        + 레코드 생성 일자 필드가 있을 경우 필드 값이 D-1인 레코드만 추출합니다.
* 암호화된 필드 중 분석에 필요한 경우 복호화
    - DIC 적재 시 DIC 암호화 방식으로 다시 암호화됩니다.
* date 타입의 포멧은 ISO 8601 사용을 권장합니다.
* null 값은 empty string ("")으로 치환해주십시오.

### 생성되는 테이블
* DIC 클러스터 하이브에 생성되는 테이블은 기본적으로 
    - 인터페이스 정의서에 암호화 요청된 필드는 DIC 규격대로 암호화되어 적재됩니다. 복호화가 필요할 경우 [위키 가이드 페이지](http://wiki.skplanet.com/pages/viewpage.action?pageId=55452400)를 참고하세요.
    - 추출 주기마다 새로운 파티션이 생성되며 추출된 레코드는 추출기준일자 기준으로 파티션에 분류되어 적재됩니다. 따라서 테이블 사용 시 delta (변동분) 또는 incremental (증분) 방식으로 추출했다면 여러 파티션을 함께 조회하셔야 합니다.